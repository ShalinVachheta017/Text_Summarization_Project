# pegasus-dialogue-summarization



# Text Summarization Project ğŸš€

> Fine-tuning PEGASUS on the SAMSum dataset to summarize conversational dialogues into short, meaningful text summaries.  
> Built with a complete ML pipeline: Research â” Modular Codebase â” API Deployment â” Dockerization.

---

## ğŸ“š Problem Statement

Modern conversations (chat, emails, messages) often contain redundant and lengthy information.  
**Text summarization** helps extract key information efficiently, saving time and effort.

This project focuses on building a **dialogue summarization system** using **Transformer-based models**.

---

## ğŸ¯ Project Goals

- Fine-tune **google/pegasus** model on real-world chat conversations (SAMSum dataset).
- Build an **end-to-end machine learning pipeline**: from data ingestion to model evaluation.
- Deploy the trained summarizer via an **API**.
- Containerize the entire application using **Docker** for easy deployment.

---

## ğŸ—ï¸ Project Architecture

| Stage | Details |
|:------|:--------|
| **Research Notebooks** | Data ingestion, validation, transformation, training, evaluation (modular Jupyter notebooks). |
| **Training Pipeline (Python scripts)** | Modularized under `src/textSummarizer/` using Clean Code principles. |
| **Configuration Management** | `params.yaml` (training parameters) and `config/config.yaml` (paths/settings). |
| **Model Serving** | `app.py` to deploy model API (FastAPI based). |
| **Docker Containerization** | `Dockerfile` for building and running the app easily. |

---

## ğŸ“‚ Project Structure

```bash
Text_Summarization_Project/
â”œâ”€â”€ .github/workflows/        # CI/CD workflows (future-ready)
â”œâ”€â”€ config/                   # Configuration files
â”‚    â””â”€â”€ config.yaml
â”œâ”€â”€ research/                 # Jupyter notebooks for research and experimentation
â”‚    â”œâ”€â”€ 01_data_ingestion.ipynb
â”‚    â”œâ”€â”€ 02_data_validation.ipynb
â”‚    â”œâ”€â”€ 03_data_transformation.ipynb
â”‚    â”œâ”€â”€ 04_model_trainer.ipynb
â”‚    â”œâ”€â”€ 05_model_evaluation.ipynb
â”‚    â”œâ”€â”€ Text_Summarization.ipynb
â”‚    â””â”€â”€ trials.ipynb
â”œâ”€â”€ src/textSummarizer/        # Core source code
â”‚    â”œâ”€â”€ components/           # Modular components (ingestion, training etc.)
â”‚    â”œâ”€â”€ config/               # Configuration parsers
â”‚    â”œâ”€â”€ constants/            # Constant values
â”‚    â”œâ”€â”€ entity/               # Data schemas
â”‚    â”œâ”€â”€ logging/              # Logging utilities
â”‚    â”œâ”€â”€ pipeline/             # Training and prediction pipelines
â”‚    â”œâ”€â”€ utils/                # Helper functions
â”‚    â””â”€â”€ __init__.py
â”œâ”€â”€ app.py                     # Serve model API
â”œâ”€â”€ main.py                    # Main runner
â”œâ”€â”€ Dockerfile                 # Docker setup
â”œâ”€â”€ setup.py                   # Package installation
â”œâ”€â”€ requirements.txt           # Project dependencies
â”œâ”€â”€ params.yaml                # Hyperparameters for training
â”œâ”€â”€ README.md                  # Project documentation
â””â”€â”€ template.py                # Folder structure generator
```

---

## ğŸ”¥ Key Features

- **Fine-tuning** PEGASUS-large model using Hugging Face Transformers.
- **Research-first Approach** with modular notebooks.
- **Production-Ready Codebase** inside `src/textSummarizer/`.
- **Config-Driven Development** using `yaml` files.
- **Containerization** with Docker for easy deployment.
- **Scalable Architecture** â€“ ready for extending to larger datasets or newer models.

---

## ğŸ›  Tech Stack

- Python 3.8+
- PyTorch
- Hugging Face Transformers
- Hugging Face Datasets
- Flask (for API serving)
- Docker
- YAML Configuration Management
- GitHub Actions (for future CI/CD)

---

## ğŸš€ How to Run Locally

### 1. Clone the repository

```bash
git clone https://github.com/ShalinVachheta017/Text_Summarization_Project.git
cd Text_Summarization_Project
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Train the Model

```bash
python main.py
```

### 4. Run the API Server

```bash
python app.py
```

The server will start at `http://127.0.0.1:5000/`.

---



Sample Input:

```
Alex: Are we still on for 6 PM?
Jordan: Running 10 minutes late, but yes!
```

Generated Summary:

> Alex and Jordan plan to meet at 6 PM, with a slight delay.

---

## âš¡ Future Work

- Deploy model on Hugging Face Spaces / Streamlit.
- Fine-tune PEGASUS on larger dialogue datasets (e.g., Reddit conversations).
- Experiment with model distillation to reduce size and improve speed.
- Add MLflow tracking for experiments and metrics.
- Add CI/CD pipeline for automatic deployment.

---

## ğŸ™‹â€â™‚ï¸ Author

- **Shalin Vachheta**  
- [GitHub](https://github.com/ShalinVachheta017) | [LinkedIn](https://linkedin.com/in/shalin-vachheta)

---

> _"Summarizing conversations is not just compression, it's distilling meaning."_ ğŸŒŸ

---

